{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ed27a9-1f9d-4f0e-b3bf-f885641cae4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 8\n",
      "train:                              unique_id         ds    y\n",
      "0     0152f69b6cf919bcdaf117aa8c43e5a2 2017-01-08  0.0\n",
      "1     0152f69b6cf919bcdaf117aa8c43e5a2 2017-01-15  0.0\n",
      "2     0152f69b6cf919bcdaf117aa8c43e5a2 2017-01-22  0.0\n",
      "3     0152f69b6cf919bcdaf117aa8c43e5a2 2017-01-29  0.0\n",
      "4     0152f69b6cf919bcdaf117aa8c43e5a2 2017-02-05  0.0\n",
      "...                                ...        ...  ...\n",
      "8561  fc1d8637c0268af3db482c14b7ef8e75 2017-12-03  1.0\n",
      "8562  fc1d8637c0268af3db482c14b7ef8e75 2017-12-10  1.0\n",
      "8563  fc1d8637c0268af3db482c14b7ef8e75 2017-12-17  0.0\n",
      "8564  fc1d8637c0268af3db482c14b7ef8e75 2017-12-24  1.0\n",
      "8565  fc1d8637c0268af3db482c14b7ef8e75 2017-12-31  1.0\n",
      "\n",
      "[5200 rows x 3 columns]\n",
      "valid:                              unique_id         ds    y\n",
      "52    0152f69b6cf919bcdaf117aa8c43e5a2 2018-01-07  2.0\n",
      "53    0152f69b6cf919bcdaf117aa8c43e5a2 2018-01-14  1.0\n",
      "54    0152f69b6cf919bcdaf117aa8c43e5a2 2018-01-21  1.0\n",
      "55    0152f69b6cf919bcdaf117aa8c43e5a2 2018-01-28  0.0\n",
      "56    0152f69b6cf919bcdaf117aa8c43e5a2 2018-02-04  0.0\n",
      "...                                ...        ...  ...\n",
      "8569  fc1d8637c0268af3db482c14b7ef8e75 2018-01-28  2.0\n",
      "8570  fc1d8637c0268af3db482c14b7ef8e75 2018-02-04  1.0\n",
      "8571  fc1d8637c0268af3db482c14b7ef8e75 2018-02-11  2.0\n",
      "8572  fc1d8637c0268af3db482c14b7ef8e75 2018-02-18  0.0\n",
      "8573  fc1d8637c0268af3db482c14b7ef8e75 2018-02-25  1.0\n",
      "\n",
      "[800 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path=\"c:\\\\temp\\\\python_play_ground\\\\sensor\\\\archive\"\n",
    "order_items = pd.read_csv(os.path.join(path, 'olist_order_items_dataset.csv'))\n",
    "orders = pd.read_csv(os.path.join(path, 'olist_orders_dataset.csv'))\n",
    "orders = orders[['order_id', 'order_purchase_timestamp']]\n",
    "data = pd.merge(order_items, orders, on='order_id')\n",
    "\n",
    "data_long = data[['product_id', 'order_purchase_timestamp', 'order_item_id']].copy()\n",
    "\n",
    "data_long['order_purchase_timestamp'] = pd.to_datetime(data_long['order_purchase_timestamp']).dt.normalize()\n",
    "data_long = data_long[data_long['order_purchase_timestamp'] >= '2017-01-01']\n",
    "data_long['week_start_date'] = (data_long['order_purchase_timestamp'] + pd.Timedelta(days=1)).apply(lambda x: x - pd.offsets.Week(weekday=6))\n",
    "\n",
    "data_grouped = data_long.groupby(['product_id', 'week_start_date'])['order_item_id'].sum().reset_index()\n",
    "\n",
    "data_grouped = data_grouped.rename(columns={'order_item_id': 'quantity_sold'})\n",
    "\n",
    "top100 = data_grouped['product_id'].value_counts().head(100).index\n",
    "data_grouped = data_grouped[data_grouped['product_id'].isin(top100)]\n",
    "\n",
    "data_pivoted = data_grouped.pivot(index='product_id', columns='week_start_date', values='quantity_sold').fillna(0)\n",
    "\n",
    "data_long = data_pivoted.stack().reset_index()\n",
    "data_long = data_long.rename(columns={'level_1': 'week_start_date', 0: 'quantity_sold'})\n",
    "\n",
    "assert data_long.groupby('product_id').size().describe()['std'] == 0\n",
    "\n",
    "data_long = data_long.rename(columns={'week_start_date': 'ds', 'quantity_sold': 'y', 'product_id': 'unique_id'})\n",
    "\n",
    "train = data_long[data_long['ds'] < '2018-01-01']\n",
    "valid = data_long[(data_long['ds'] >= '2018-01-01') & (data_long['ds'] < '2018-03-01')]\n",
    "h = valid['ds'].nunique()\n",
    "print('h =', h)\n",
    "\n",
    "print('train:', train)\n",
    "print('valid:', valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93a27dd-5c22-4143-b4cb-90d168be3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\statsforecast\\core.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive, SeasonalNaive, WindowAverage, SeasonalWindowAverage\n",
    "\n",
    "model = StatsForecast(models=[Naive(), \n",
    "                              SeasonalNaive(season_length=4), \n",
    "                              WindowAverage(window_size=4), \n",
    "                              SeasonalWindowAverage(window_size=2, season_length=4)],\n",
    "                      freq='W', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc64984-51ab-48fe-8abc-9ca99faed1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsForecast(models=[Naive,SeasonalNaive,WindowAverage,SeasWA])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6552733c-4ee9-4745-8f60-c74880d861f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\statsforecast\\core.py:399: FutureWarning: The `df` argument of the StatsForecast constructor as well as reusing stored dfs from other methods is deprecated and will raise an error in a future version. Please provide the `df` argument to the corresponding method instead, e.g. fit/forecast.\n",
      "  warnings.warn(\n",
      "C:\\tools\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\statsforecast\\core.py:417: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "p = model.forecast(h=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5290571-1bc8-41bd-8c61-f31cac24b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, HoltWinters\n",
    "\n",
    "model = StatsForecast(models=[AutoARIMA(season_length=4),\n",
    "                              HoltWinters(season_length=4, error_type='A')],\n",
    "                      freq='W', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ebe6aa5-6318-44ee-8544-af5bca3b751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\statsforecast\\core.py:399: FutureWarning: The `df` argument of the StatsForecast constructor as well as reusing stored dfs from other methods is deprecated and will raise an error in a future version. Please provide the `df` argument to the corresponding method instead, e.g. fit/forecast.\n",
      "  warnings.warn(\n",
      "C:\\tools\\WPy64-31180\\python-3.11.8.amd64\\Lib\\site-packages\\statsforecast\\core.py:417: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.fit(train)\n",
    "\n",
    "p = model.forecast(h=h, level=[90])\n",
    "\n",
    "cols = p.columns[1:]\n",
    "p.loc[:, cols] = p.loc[:, cols].clip(0)\n",
    "p = p.reset_index().merge(valid, on=['ds', 'unique_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ad93e-2fee-4baf-9b2d-b1090a84ad75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
